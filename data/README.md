# Data Directory

This directory contains all data assets for the ProdSegmenter project, organized into raw and processed datasets.

## ğŸ“ Directory Structure

```
data/
â”œâ”€â”€ raw/                    # Raw, unprocessed data
â”‚   â”œâ”€â”€ videos/            # Original video files
â”‚   â””â”€â”€ images/            # Individual image frames
â””â”€â”€ processed/             # Processed and prepared data
    â”œâ”€â”€ frames/            # Extracted video frames
    â”œâ”€â”€ masks/             # Generated segmentation masks
    â””â”€â”€ annotations/       # Annotation files and metadata
```

## ğŸ¯ Purpose

### Raw Data (`raw/`)
- **Videos**: Upload your grocery shelf videos here (.mp4, .avi, .mov, .mkv)
- **Images**: Individual frames or photos for testing and validation
- **Source**: Original data without any preprocessing or modifications

### Processed Data (`processed/`)
- **Frames**: Video frames extracted at target FPS (30-60 FPS)
- **Masks**: Segmentation masks generated by SAM and custom models
- **Annotations**: JSON files with bounding boxes, class labels, and metadata

## ğŸ”§ Usage Guidelines

### Adding New Data
1. Place raw videos in `raw/videos/`
2. Run preprocessing notebooks to extract frames
3. Use SAM bootstrap notebook to generate initial masks
4. Processed data will be automatically organized in `processed/`

### Data Format Requirements
- **Videos**: MP4, AVI, MOV, MKV formats
- **Resolution**: Minimum 640x480, recommended 1920x1080
- **Frame Rate**: 30-60 FPS for real-time processing
- **Duration**: 10 seconds to 10 minutes per video

### File Naming Convention
```
raw/videos/store_[store_id]_shelf_[shelf_id]_[timestamp].mp4
processed/frames/store_[store_id]_shelf_[shelf_id]_frame_[number].jpg
processed/masks/store_[store_id]_shelf_[shelf_id]_frame_[number]_mask.png
```

## ğŸ“Š Data Organization

### Video Processing Pipeline
1. **Upload**: Raw videos â†’ `raw/videos/`
2. **Extract**: Frames â†’ `processed/frames/`
3. **Segment**: SAM masks â†’ `processed/masks/`
4. **Annotate**: Labels â†’ `processed/annotations/`

### Expected Data Sizes
- Raw videos: 100MB - 2GB per video
- Processed frames: 1-5MB per frame
- Masks: 100KB - 1MB per mask
- Total project size: 50-500GB depending on dataset

## ğŸ”’ Data Security

- Raw data is excluded from Git via `.gitignore`
- Use Azure Blob Storage for large dataset storage
- Implement data versioning for reproducibility
- Follow data privacy guidelines for retail environments

## ğŸ“‹ Quality Checklist

- [ ] Videos have adequate lighting and resolution
- [ ] Products are clearly visible on shelves
- [ ] Multiple angles and shelf arrangements included
- [ ] Diverse product categories represented
- [ ] Consistent frame rate and quality

## ğŸš€ Quick Start

```bash
# Extract frames from videos
cd notebooks/
jupyter lab 03_preprocessing.ipynb

# Generate SAM masks
jupyter lab 02_sam_bootstrap.ipynb

# Check data quality
python -c "from pathlib import Path; print(f'Videos: {len(list(Path('raw/videos').glob('*.mp4')))}'); print(f'Frames: {len(list(Path('processed/frames').glob('*.jpg')))}')"
```

For detailed data processing instructions, see the notebooks in the `notebooks/` directory. 